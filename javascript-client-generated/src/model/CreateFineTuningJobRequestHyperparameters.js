/*
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.0.0
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 *
 * Swagger Codegen version: 3.0.50
 *
 * Do not edit the class manually.
 *
 */
import {ApiClient} from '../ApiClient';

/**
 * The CreateFineTuningJobRequestHyperparameters model module.
 * @module model/CreateFineTuningJobRequestHyperparameters
 * @version 2.0.0
 */
export class CreateFineTuningJobRequestHyperparameters {
  /**
   * Constructs a new <code>CreateFineTuningJobRequestHyperparameters</code>.
   * The hyperparameters used for the fine-tuning job.
   * @alias module:model/CreateFineTuningJobRequestHyperparameters
   * @class
   */
  constructor() {
  }

  /**
   * Constructs a <code>CreateFineTuningJobRequestHyperparameters</code> from a plain JavaScript object, optionally creating a new instance.
   * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
   * @param {Object} data The plain JavaScript object bearing properties of interest.
   * @param {module:model/CreateFineTuningJobRequestHyperparameters} obj Optional instance to populate.
   * @return {module:model/CreateFineTuningJobRequestHyperparameters} The populated <code>CreateFineTuningJobRequestHyperparameters</code> instance.
   */
  static constructFromObject(data, obj) {
    if (data) {
      obj = obj || new CreateFineTuningJobRequestHyperparameters();
      if (data.hasOwnProperty('batch_size'))
        obj.batchSize = ApiClient.convertToType(data['batch_size'], Object);
      if (data.hasOwnProperty('learning_rate_multiplier'))
        obj.learningRateMultiplier = ApiClient.convertToType(data['learning_rate_multiplier'], Object);
      if (data.hasOwnProperty('n_epochs'))
        obj.nEpochs = ApiClient.convertToType(data['n_epochs'], Object);
    }
    return obj;
  }
}

/**
 * Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance. 
 * @member {Object} batchSize
 */
CreateFineTuningJobRequestHyperparameters.prototype.batchSize = undefined;

/**
 * Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting. 
 * @member {Object} learningRateMultiplier
 */
CreateFineTuningJobRequestHyperparameters.prototype.learningRateMultiplier = undefined;

/**
 * The number of epochs to train the model for. An epoch refers to one full cycle  through the training dataset. 
 * @member {Object} nEpochs
 */
CreateFineTuningJobRequestHyperparameters.prototype.nEpochs = undefined;

