/*
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.0.0
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 *
 * Swagger Codegen version: 3.0.50
 *
 * Do not edit the class manually.
 *
 */
import {ApiClient} from '../ApiClient';

/**
 * The FineTuneHyperparams model module.
 * @module model/FineTuneHyperparams
 * @version 2.0.0
 */
export class FineTuneHyperparams {
  /**
   * Constructs a new <code>FineTuneHyperparams</code>.
   * The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/legacy-fine-tuning/hyperparameters) for more details.
   * @alias module:model/FineTuneHyperparams
   * @class
   * @param batchSize {Number} The batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass. 
   * @param learningRateMultiplier {Number} The learning rate multiplier to use for training. 
   * @param nEpochs {Number} The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset. 
   * @param promptLossWeight {Number} The weight to use for loss on the prompt tokens. 
   */
  constructor(batchSize, learningRateMultiplier, nEpochs, promptLossWeight) {
    this.batchSize = batchSize;
    this.learningRateMultiplier = learningRateMultiplier;
    this.nEpochs = nEpochs;
    this.promptLossWeight = promptLossWeight;
  }

  /**
   * Constructs a <code>FineTuneHyperparams</code> from a plain JavaScript object, optionally creating a new instance.
   * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
   * @param {Object} data The plain JavaScript object bearing properties of interest.
   * @param {module:model/FineTuneHyperparams} obj Optional instance to populate.
   * @return {module:model/FineTuneHyperparams} The populated <code>FineTuneHyperparams</code> instance.
   */
  static constructFromObject(data, obj) {
    if (data) {
      obj = obj || new FineTuneHyperparams();
      if (data.hasOwnProperty('batch_size'))
        obj.batchSize = ApiClient.convertToType(data['batch_size'], 'Number');
      if (data.hasOwnProperty('classification_n_classes'))
        obj.classificationNClasses = ApiClient.convertToType(data['classification_n_classes'], 'Number');
      if (data.hasOwnProperty('classification_positive_class'))
        obj.classificationPositiveClass = ApiClient.convertToType(data['classification_positive_class'], 'String');
      if (data.hasOwnProperty('compute_classification_metrics'))
        obj.computeClassificationMetrics = ApiClient.convertToType(data['compute_classification_metrics'], 'Boolean');
      if (data.hasOwnProperty('learning_rate_multiplier'))
        obj.learningRateMultiplier = ApiClient.convertToType(data['learning_rate_multiplier'], 'Number');
      if (data.hasOwnProperty('n_epochs'))
        obj.nEpochs = ApiClient.convertToType(data['n_epochs'], 'Number');
      if (data.hasOwnProperty('prompt_loss_weight'))
        obj.promptLossWeight = ApiClient.convertToType(data['prompt_loss_weight'], 'Number');
    }
    return obj;
  }
}

/**
 * The batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass. 
 * @member {Number} batchSize
 */
FineTuneHyperparams.prototype.batchSize = undefined;

/**
 * The number of classes to use for computing classification metrics. 
 * @member {Number} classificationNClasses
 */
FineTuneHyperparams.prototype.classificationNClasses = undefined;

/**
 * The positive class to use for computing classification metrics. 
 * @member {String} classificationPositiveClass
 */
FineTuneHyperparams.prototype.classificationPositiveClass = undefined;

/**
 * The classification metrics to compute using the validation dataset at the end of every epoch. 
 * @member {Boolean} computeClassificationMetrics
 */
FineTuneHyperparams.prototype.computeClassificationMetrics = undefined;

/**
 * The learning rate multiplier to use for training. 
 * @member {Number} learningRateMultiplier
 */
FineTuneHyperparams.prototype.learningRateMultiplier = undefined;

/**
 * The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset. 
 * @member {Number} nEpochs
 */
FineTuneHyperparams.prototype.nEpochs = undefined;

/**
 * The weight to use for loss on the prompt tokens. 
 * @member {Number} promptLossWeight
 */
FineTuneHyperparams.prototype.promptLossWeight = undefined;

