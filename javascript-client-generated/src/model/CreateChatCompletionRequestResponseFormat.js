/*
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * OpenAPI spec version: 2.0.0
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 *
 * Swagger Codegen version: 3.0.50
 *
 * Do not edit the class manually.
 *
 */
import {ApiClient} from '../ApiClient';

/**
 * The CreateChatCompletionRequestResponseFormat model module.
 * @module model/CreateChatCompletionRequestResponseFormat
 * @version 2.0.0
 */
export class CreateChatCompletionRequestResponseFormat {
  /**
   * Constructs a new <code>CreateChatCompletionRequestResponseFormat</code>.
   * An object specifying the format that the model must output. Used to enable JSON mode.
   * @alias module:model/CreateChatCompletionRequestResponseFormat
   * @class
   */
  constructor() {
  }

  /**
   * Constructs a <code>CreateChatCompletionRequestResponseFormat</code> from a plain JavaScript object, optionally creating a new instance.
   * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
   * @param {Object} data The plain JavaScript object bearing properties of interest.
   * @param {module:model/CreateChatCompletionRequestResponseFormat} obj Optional instance to populate.
   * @return {module:model/CreateChatCompletionRequestResponseFormat} The populated <code>CreateChatCompletionRequestResponseFormat</code> instance.
   */
  static constructFromObject(data, obj) {
    if (data) {
      obj = obj || new CreateChatCompletionRequestResponseFormat();
      if (data.hasOwnProperty('type'))
        obj.type = ApiClient.convertToType(data['type'], 'String');
    }
    return obj;
  }
}

/**
 * Allowed values for the <code>type</code> property.
 * @enum {String}
 * @readonly
 */
CreateChatCompletionRequestResponseFormat.TypeEnum = {
  /**
   * value: "text"
   * @const
   */
  text: "text",

  /**
   * value: "json_object"
   * @const
   */
  jsonObject: "json_object"
};
/**
 * Setting to `json_object` enables JSON mode. This guarantees that the message the model generates is valid JSON.   Note that your system prompt must still instruct the model to produce JSON, and to help ensure you don't forget, the API will throw an error if the string `JSON` does not appear in your system message. Also note that the message content may be partial (i.e. cut off) if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.   Must be one of `text` or `json_object`. 
 * @member {module:model/CreateChatCompletionRequestResponseFormat.TypeEnum} type
 * @default 'text'
 */
CreateChatCompletionRequestResponseFormat.prototype.type = 'text';

